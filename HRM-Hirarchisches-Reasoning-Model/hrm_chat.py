#!/usr/bin/env python3
"""
HRM Chat Interface fÃ¼r Trae
Diese Datei ermÃ¶glicht die direkte Kommunikation mit Ihrem lokalen HRM-Modell
Ã¼ber die OpenAI-kompatible API. Sie kÃ¶nnen sie direkt in Trae ausfÃ¼hren.
"""

import requests
import json
import sys
from typing import List, Dict, Optional

class HRMChat:
    def __init__(self, base_url="http://127.0.0.1:8000"):
        self.base_url = base_url
        self.model = "hrm-local-model"
        self.conversation_history: List[Dict[str, str]] = []
    
    def chat(self, message: str, system_prompt: Optional[str] = None) -> str:
        """Sendet eine Nachricht an das HRM-Modell und gibt die Antwort zurÃ¼ck."""
        
        # Erstelle die Messages-Struktur
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        
        # FÃ¼ge Konversationshistorie hinzu
        messages.extend(self.conversation_history)
        messages.append({"role": "user", "content": message})
        
        # API-Anfrage
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": 2000,
            "temperature": 0.7
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            assistant_message = result["choices"][0]["message"]["content"]
            
            # Speichere die Nachrichten in der Historie
            self.conversation_history.append({"role": "user", "content": message})
            self.conversation_history.append({"role": "assistant", "content": assistant_message})
            
            # Begrenze die Historie auf die letzten 10 Nachrichten
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
            
            return assistant_message
            
        except requests.exceptions.ConnectionError:
            return "âŒ Fehler: HRM-Server nicht erreichbar. Stelle sicher, dass 'openai_proxy_server.py' lÃ¤uft."
        except Exception as e:
            return f"âŒ Fehler: {str(e)}"
    
    def clear_history(self):
        """LÃ¶scht die Konversationshistorie."""
        self.conversation_history = []
    
    def research_mode(self, topic: str) -> str:
        """Spezialmodus fÃ¼r tiefgreifende Recherche."""
        system_prompt = """Du bist ein Experte fÃ¼r tiefgrÃ¼ndige Recherche und Analyse. 
        Strukturiere deine Antworten klar und tiefgrÃ¼ndig. BerÃ¼cksichtige verschiedene Perspektiven 
        und liefere konkrete, umsetzbare Erkenntnisse."""
        
        return self.chat(f"Bitte analysiere folgendes Thema tiefgrÃ¼ndig: {topic}", system_prompt)
    
    def brainstorm_mode(self, problem: str) -> str:
        """Spezialmodus fÃ¼r Brainstorming und kreative LÃ¶sungen."""
        system_prompt = """Du bist ein kreativer Brainstorming-Partner. Denke unkonventionell 
        und liefere innovative, aber praktikable LÃ¶sungsansÃ¤tze. Sei mutig in deinen Ideen."""
        
        return self.chat(f"Brainstorming-Auftrag: {problem}", system_prompt)
    
    def code_mode(self, code_context: str, request: str) -> str:
        """Spezialmodus fÃ¼r Code-Analyse und -Verbesserung."""
        system_prompt = """Du bist ein erfahrener Software-Entwickler. Analysiere Code 
        grÃ¼ndlich und gib prÃ¤zise, umsetzbare VerbesserungsvorschlÃ¤ge."""
        
        return self.chat(f"Code-Kontext: {code_context}\n\nAnfrage: {request}", system_prompt)

# Interaktive Nutzung im Terminal
if __name__ == "__main__":
    chat = HRMChat()
    
    print("ğŸ§  HRM Chat Interface gestartet")
    print("ğŸ’¡ Tipp: Der Server lÃ¤uft auf http://127.0.0.1:8000")
    print("ğŸ“ Befehle: 'exit' zum Beenden, 'clear' zum LÃ¶schen der Historie")
    print("ğŸ¯ Modi: 'research <Thema>', 'brainstorm <Problem>', 'code <Code> <Frage>'")
    print("-" * 50)
    
    mode = None
    
    while True:
        try:
            user_input = input("\nğŸ’¬ Du: ").strip()
            
            if user_input.lower() == 'exit':
                print("ğŸ‘‹ Auf Wiedersehen!")
                break
            elif user_input.lower() == 'clear':
                chat.clear_history()
                print("ğŸ—‘ï¸ Historie gelÃ¶scht!")
                continue
            elif user_input.startswith('research '):
                response = chat.research_mode(user_input[9:])
                print(f"ğŸ” HRM: {response}")
                continue
            elif user_input.startswith('brainstorm '):
                response = chat.brainstorm_mode(user_input[11:])
                print(f"ğŸ’¡ HRM: {response}")
                continue
            elif user_input.startswith('code '):
                parts = user_input[5:].split(' ', 1)
                if len(parts) == 2:
                    response = chat.code_mode(parts[0], parts[1])
                    print(f"ğŸ’» HRM: {response}")
                else:
                    print("âŒ Syntax: code <Code-Datei-Inhalt> <Frage>")
                continue
            
            response = chat.chat(user_input)
            print(f"ğŸ¤– HRM: {response}")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Auf Wiedersehen!")
            break
        except Exception as e:
            print(f"âŒ Fehler: {e}")